# Generated by nuclio.export.NuclioExporter

import warnings

warnings.simplefilter(action="ignore", category=FutureWarning)

import json
import numpy as np
import requests
from tensorflow import keras
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import load_img
from os import environ, path
from PIL import Image
from io import BytesIO
from urllib.request import urlopen
import mlrun


class TFModel(mlrun.serving.V2ModelServer):
    def load(self):
        self.IMAGE_WIDTH = int(environ.get("IMAGE_WIDTH", "128"))
        self.IMAGE_HEIGHT = int(environ.get("IMAGE_HEIGHT", "128"))

        try:
            with open(environ["classes_map"], "r") as f:
                self.classes = json.load(f)
        except:
            self.classes = None

        model_file, extra_data = self.get_model(".h5")
        self.model = load_model(model_file)

    def preprocess(self, body, operation):
        try:
            output = {"inputs": []}
            inputs = body.get("inputs", [])
            for byte_image in inputs:
                img = Image.open(byte_image)
                img = img.resize((self.IMAGE_WIDTH, self.IMAGE_HEIGHT))

                x = image.img_to_array(img)
                x = np.expand_dims(x, axis=0)
                output["inputs"].append(x)

            output["inputs"] = [np.vstack(output["inputs"])]
            return output
        except:
            raise Exception(f"received: {body}")

    def predict(self, data):
        images = data.get("inputs", [])

        predicted_probability = self.model.predict(images)

        return predicted_probability.tolist()[0]


from mlrun.runtimes import nuclio_init_hook


def init_context(context):
    nuclio_init_hook(context, globals(), "serving_v2")


def handler(context, event):
    return context.mlrun_handler(context, event)
